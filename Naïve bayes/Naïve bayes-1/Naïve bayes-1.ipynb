{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaa71e1b-51d2-476f-9927-2851f6bd6c32",
   "metadata": {},
   "source": [
    "**Q1. What is Bayes' theorem?**\n",
    "\n",
    "Bayes' theorem is a fundamental concept in probability theory and statistics, named after the Reverend Thomas Bayes. It describes the probability of an event, based on prior knowledge of conditions that might be related to the event. In other words, Bayes' theorem provides a way to update our beliefs about the likelihood of an event occurring, given new evidence.\n",
    "\n",
    "**Q2. What is the formula for Bayes' theorem?**\n",
    "\n",
    "Bayes' theorem is mathematically represented as:\n",
    "\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)} \\]\n",
    "\n",
    "Where:\n",
    "- \\( P(A|B) \\) is the conditional probability of event A occurring given that event B has occurred.\n",
    "- \\( P(B|A) \\) is the conditional probability of event B occurring given that event A has occurred.\n",
    "- \\( P(A) \\) and \\( P(B) \\) are the probabilities of events A and B occurring independently.\n",
    "\n",
    "**Q3. How is Bayes' theorem used in practice?**\n",
    "\n",
    "Bayes' theorem is used in various fields, including statistics, machine learning, and decision-making. In practice, it is applied in:\n",
    "\n",
    "- Bayesian inference: Updating prior beliefs with new evidence to make more accurate predictions or estimates.\n",
    "- Bayesian statistics: Using probability distributions to quantify uncertainty in statistical models.\n",
    "- Naive Bayes classification: Classifying data points based on conditional probabilities.\n",
    "\n",
    "**Q4. What is the relationship between Bayes' theorem and conditional probability?**\n",
    "\n",
    "Bayes' theorem relates conditional probabilities. It provides a way to calculate the conditional probability of an event \\( A \\) given that another event \\( B \\) has occurred, based on the conditional probability of \\( B \\) given \\( A \\) and the prior probabilities of \\( A \\) and \\( B \\). Essentially, Bayes' theorem formalizes how to update our beliefs about the likelihood of an event occurring based on new evidence.\n",
    "\n",
    "**Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?**\n",
    "\n",
    "The choice of Naive Bayes classifier depends on the nature of the problem and the assumptions about the independence of features. Common types of Naive Bayes classifiers include Gaussian Naive Bayes, Multinomial Naive Bayes, and Bernoulli Naive Bayes. Here are some considerations:\n",
    "- Gaussian Naive Bayes: Suitable for continuous numerical features that follow a Gaussian distribution.\n",
    "- Multinomial Naive Bayes: Suitable for features representing counts or frequencies, often used in text classification.\n",
    "- Bernoulli Naive Bayes: Suitable for features that are binary (present or absent), typically used for document classification tasks.\n",
    "\n",
    "**Q6. Assignment:**\n",
    "\n",
    "To predict the class for the new instance with features \\( X_1 = 3 \\) and \\( X_2 = 4 \\), we can use the Naive Bayes classifier with the given frequency table. We'll calculate the conditional probabilities for each class and then apply Bayes' theorem to make the prediction.\n",
    "\n",
    "Using the given frequency table:\n",
    "\n",
    "\\[ P(X_1=3 | A) = \\frac{4}{10} \\]\n",
    "\\[ P(X_1=3 | B) = \\frac{1}{9} \\]\n",
    "\\[ P(X_2=4 | A) = \\frac{3}{10} \\]\n",
    "\\[ P(X_2=4 | B) = \\frac{3}{9} \\]\n",
    "\n",
    "Assuming equal prior probabilities for each class:\n",
    "\n",
    "\\[ P(A) = P(B) = \\frac{1}{2} \\]\n",
    "\n",
    "Now, let's apply Bayes' theorem to calculate the posterior probabilities for classes A and B:\n",
    "\n",
    "For class A:\n",
    "\\[ P(A | X_1=3, X_2=4) = \\frac{P(X_1=3 | A) \\times P(X_2=4 | A) \\times P(A)}{P(X_1=3) \\times P(X_2=4)} \\]\n",
    "\n",
    "For class B:\n",
    "\\[ P(B | X_1=3, X_2=4) = \\frac{P(X_1=3 | B) \\times P(X_2=4 | B) \\times P(B)}{P(X_1=3) \\times P(X_2=4)} \\]\n",
    "\n",
    "We'll calculate these probabilities and choose the class with the higher posterior probability as the predicted class for the new instance. Let's proceed with the calculations.\n",
    "\n",
    "To calculate the posterior probabilities for classes A and B, we need to compute \\( P(X_1=3) \\) and \\( P(X_2=4) \\) first, as they appear in the denominators of both Bayes' theorem equations. We can compute these probabilities by summing the conditional probabilities over all classes.\n",
    "\n",
    "\\[ P(X_1=3) = P(X_1=3 | A) \\times P(A) + P(X_1=3 | B) \\times P(B) \\]\n",
    "\\[ P(X_2=4) = P(X_2=4 | A) \\times P(A) + P(X_2=4 | B) \\times P(B) \\]\n",
    "\n",
    "Let's compute these probabilities and then proceed with calculating the posterior probabilities for classes A and B.\n",
    "\n",
    "First, let's compute \\( P(X_1=3) \\) and \\( P(X_2=4) \\):\n",
    "\n",
    "\\[ P(X_1=3) = P(X_1=3 | A) \\times P(A) + P(X_1=3 | B) \\times P(B) \\]\n",
    "\\[ P(X_1=3) = \\frac{4}{10} \\times \\frac{1}{2} + \\frac{1}{9} \\times \\frac{1}{2} \\]\n",
    "\\[ P(X_1=3) = \\frac{2}{10} + \\frac{1}{18} \\]\n",
    "\\[ P(X_1=3) = \\frac{9}{45} + \\frac{5}{45} \\]\n",
    "\\[ P(X_1=3) = \\frac{14}{45} \\]\n",
    "\n",
    "\\[ P(X_2=4) = P(X_2=4 | A) \\times P(A) + P(X_2=4 | B) \\times P(B) \\]\n",
    "\\[ P(X_2=4) = \\frac{3}{10} \\times \\frac{1}{2} + \\frac{3}{9} \\times \\frac{1}{2} \\]\n",
    "\\[ P(X_2=4) = \\frac{3}{20} + \\frac{1}{6} \\]\n",
    "\\[ P(X_2=4) = \\frac{9}{60} + \\frac{10}{60} \\]\n",
    "\\[ P(X_2=4) = \\frac{19}{60} \\]\n",
    "\n",
    "Now that we have \\( P(X_1=3) \\) and \\( P(X_2=4) \\), let's compute the posterior probabilities for classes A and B:\n",
    "\n",
    "For class A:\n",
    "\\[ P(A | X_1=3, X_2=4) = \\frac{P(X_1=3 | A) \\times P(X_2=4 | A) \\times P(A)}{P(X_1=3) \\times P(X_2=4)} \\]\n",
    "\\[ P(A | X_1=3, X_2=4) = \\frac{\\frac{4}{10} \\times \\frac{3}{10} \\times \\frac{1}{2}}{\\frac{14}{45} \\times \\frac{19}{60}} \\]\n",
    "\\[ P(A | X_1=3, X_2=4) = \\frac{\\frac{12}{100} \\times \\frac{1}{2}}{\\frac{133}{300}} \\]\n",
    "\\[ P(A | X_1=3, X_2=4) = \\frac{\\frac{6}{100}}{\\frac{133}{300}} \\]\n",
    "\\[ P(A | X_1=3, X_2=4) = \\frac{6}{133} \\approx 0.0451 \\]\n",
    "\n",
    "For class B:\n",
    "\\[ P(B | X_1=3, X_2=4) = \\frac{P(X_1=3 | B) \\times P(X_2=4 | B) \\times P(B)}{P(X_1=3) \\times P(X_2=4)} \\]\n",
    "\\[ P(B | X_1=3, X_2=4) = \\frac{\\frac{1}{9} \\times \\frac{3}{9} \\times \\frac{1}{2}}{\\frac{14}{45} \\times \\frac{19}{60}} \\]\n",
    "\\[ P(B | X_1=3, X_2=4) = \\frac{\\frac{3}{81} \\times \\frac{1}{2}}{\\frac{133}{300}} \\]\n",
    "\\[ P(B | X_1=3, X_2=4) = \\frac{\\frac{3}{162}}{\\frac{133}{300}} \\]\n",
    "\\[ P(B | X_1=3, X_2=4) = \\frac{3}{266} \\approx 0.0113 \\]\n",
    "\n",
    "Now that we have computed the posterior probabilities for classes A and B, let's compare them and predict the class for the new instance.\n",
    "\n",
    "We have computed the posterior probabilities as follows:\n",
    "\n",
    "- \\( P(A | X_1=3, X_2=4) \\approx 0.0451 \\)\n",
    "- \\( P(B | X_1=3, X_2=4) \\approx 0.0113 \\)\n",
    "\n",
    "Since \\( P(A | X_1=3, X_2=4) > P(B | X_1=3, X_2=4) \\), we predict that the new instance with features \\( X_1 = 3 \\) and \\( X_2 = 4 \\) belongs to class A (diabetic) according to the Naive Bayes classifier.\n",
    "\n",
    "This prediction is made based on the posterior probabilities computed using Bayes' theorem and the given class frequency table, assuming equal prior probabilities for each class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
