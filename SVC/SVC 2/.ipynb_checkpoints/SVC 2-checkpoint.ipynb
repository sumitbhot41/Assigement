{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ce9e70e2-a5aa-4f53-9c7e-dd812a778c7e",
   "metadata": {},
   "source": [
    "Q1. Polynomial functions and kernel functions in machine learning algorithms are related through their use in Support Vector Machines (SVMs). In SVMs, kernel functions are used to implicitly map input data into higher-dimensional feature spaces where linear separation might be more feasible. Polynomial kernel functions are a type of kernel function used in SVMs, which compute the inner product of vectors in a feature space generated by polynomial combinations of the original features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ebe88-cf31-4ee9-874e-b2ab8fd4e949",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Here's how you can implement an SVM with a polynomial kernel in Python using Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eee1467b-ff2d-45f8-b73e-c3d6d3daaa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset (example using Iris dataset)\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Preprocess the data (scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an instance of SVC classifier with polynomial kernel\n",
    "svm_classifier = SVC(kernel='poly')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict the labels of the testing data\n",
    "y_pred = svm_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94fc09dd-300f-419b-bb8e-825c12b73f79",
   "metadata": {},
   "source": [
    "Q3. Increasing the value of epsilon in Support Vector Regression (SVR) typically leads to fewer support vectors. This is because a larger epsilon allows for a wider margin of tolerance for errors, thus reducing the need for additional support vectors to fit the data within the margin"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2ea4580-f8cb-40d0-bc63-9b579192f732",
   "metadata": {},
   "source": [
    "Choice of kernel function: Different kernel functions (e.g., linear, polynomial, radial basis function) can have varying effects on the performance of SVR. The choice depends on the underlying data and problem at hand. For example, if the data has a linear structure, a linear kernel might work well, while for non-linear relationships, polynomial or RBF kernels might be more appropriate.\n",
    "C parameter: It controls the trade-off between achieving a low training error and a low model complexity (smoothness). Higher values of C allow for a smaller margin and penalize misclassifications more heavily, potentially leading to overfitting.\n",
    "Epsilon parameter: It determines the width of the epsilon-tube within which no penalty is associated in the loss function. Increasing epsilon allows for more errors to be tolerated, potentially reducing the number of support vectors.\n",
    "Gamma parameter: It defines the influence of a single training example, with low values meaning 'far' and high values meaning 'close'. Higher values of gamma lead to more complex decision boundaries, potentially resulting in overfitting for small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f84c24-fcac-47da-bc2f-2b6c5f68db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Here's the assignment solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3ccb5e1-09e3-4f4f-9347-22e15a664c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'gamma': 1, 'kernel': 'poly'}\n",
      "Accuracy: 0.9777777777777777\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Train the tuned classifier on the entire dataset\u001b[39;00m\n\u001b[0;32m     42\u001b[0m final_classifier \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m---> 43\u001b[0m final_classifier\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_scaled\u001b[49m, y)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Save the trained classifier to a file for future use\u001b[39;00m\n\u001b[0;32m     46\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(final_classifier, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvm_classifier.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Load dataset (using Iris dataset)\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Preprocess the data (scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an instance of SVC classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Tune hyperparameters using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10, 100],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001],\n",
    "              'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=svm_classifier, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the performance of the tuned classifier\n",
    "y_pred = grid_search.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Train the tuned classifier on the entire dataset\n",
    "final_classifier = grid_search.best_estimator_\n",
    "final_classifier.fit(X_scaled, y)\n",
    "\n",
    "# Save the trained classifier to a file for future use\n",
    "joblib.dump(final_classifier, 'svm_classifier.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817aed46-4f26-4dcf-9d5d-c2c498502d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0821a8-7f3e-4a9c-8395-aa21a8a3a51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875a5fba-1ac6-4d5f-9a3c-140ae930fe97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ded9699-7f20-4b0b-909c-ca1dec7b83bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47abe2f5-1e3f-4442-b901-05719b011a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aea0f5-63f7-4b7e-8452-696d01df8a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f274bdcf-601c-4f53-b6b8-b619468964a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2606a9-cbc3-4983-9105-81ce73bf7e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cdd547-ece5-465f-929a-72de5cb2740d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b349d501-9eb8-455b-808a-da5961ab17b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0402c65-dbe8-422e-ac14-b8952b068dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7136ad1-de76-48fb-81be-4b062fa59cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bb54e0-1bfd-472b-b5f3-ba7c51bc619e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2078584f-3a53-4bae-9e15-88a8f3e13dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687ac5a4-22e4-43cc-874a-59aeeecf488a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b00889-e879-44a6-8300-43567f15b4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af211975-0d76-4bd6-853b-4f187abf35bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cabcf20-83d8-4d69-9f0a-3eefe46ce184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde3f688-8a2c-4746-b4c7-7d821fa34849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64d8f09-7805-41e2-a257-c244acc34e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a54f582-8643-4785-8146-94ddafb62fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
