{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656d8da3-b316-4ed2-bb6a-0dbcc2c78f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Random Forest Regressor?\n",
    "Q2. How does Random Forest Regressor reduce the risk of overfitting?\n",
    "Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n",
    "Q4. What are the hyperparameters of Random Forest Regressor?\n",
    "Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?\n",
    "Q6. What are the advantages and disadvantages of Random Forest Regressor?\n",
    "Q7. What is the output of Random Forest Regressor?\n",
    "Q8. Can Random Forest Regressor be used for classification tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500b5200-fa1d-412a-88b2-1ccb097903b7",
   "metadata": {},
   "source": [
    "Q1. Random Forest Regressor is a machine learning algorithm used for regression tasks. It is an ensemble learning method that builds multiple decision trees during training and outputs the average prediction (or the mode in classification tasks) of the individual trees as the final prediction.\n",
    "\n",
    "Q2. Random Forest Regressor reduces the risk of overfitting through several mechanisms:\n",
    "   - Random feature selection: Each decision tree in the random forest is trained on a random subset of features, reducing the chance of any single feature dominating the decision-making process.\n",
    "   - Bagging (Bootstrap Aggregating): Random Forest combines multiple decision trees trained on different subsets of the training data, thereby reducing the variance of the model.\n",
    "   - Max depth: Controlling the maximum depth of each decision tree helps prevent them from becoming overly complex and capturing noise in the data.\n",
    "\n",
    "Q3. Random Forest Regressor aggregates the predictions of multiple decision trees by averaging the predictions (or taking the mode in classification tasks) of all individual trees. This ensemble approach helps to improve the overall prediction accuracy and generalization of the model.\n",
    "\n",
    "Q4. The hyperparameters of Random Forest Regressor include:\n",
    "   - `n_estimators`: The number of decision trees in the forest.\n",
    "   - `max_depth`: The maximum depth of each decision tree.\n",
    "   - `min_samples_split`: The minimum number of samples required to split an internal node.\n",
    "   - `min_samples_leaf`: The minimum number of samples required to be at a leaf node.\n",
    "   - `max_features`: The number of features to consider when looking for the best split.\n",
    "   - `bootstrap`: Whether bootstrap samples are used when building trees.\n",
    "   - `random_state`: Seed for random number generation.\n",
    "\n",
    "Q5. The main differences between Random Forest Regressor and Decision Tree Regressor are:\n",
    "   - Random Forest Regressor builds multiple decision trees and averages their predictions, while Decision Tree Regressor builds a single decision tree.\n",
    "   - Random Forest Regressor reduces overfitting by averaging multiple trees, whereas Decision Tree Regressor is prone to overfitting, especially if the tree is deep.\n",
    "   - Random Forest Regressor typically provides better generalization performance compared to a single Decision Tree Regressor.\n",
    "\n",
    "Q6. Advantages of Random Forest Regressor:\n",
    "   - Handles high-dimensional data well.\n",
    "   - Less prone to overfitting compared to individual decision trees.\n",
    "   - Robust to noisy data and outliers.\n",
    "   - Provides feature importances for interpretation.\n",
    "   \n",
    "   Disadvantages of Random Forest Regressor:\n",
    "   - Can be computationally expensive, especially with a large number of trees.\n",
    "   - Less interpretable compared to a single decision tree.\n",
    "   - May not perform well with imbalanced datasets.\n",
    "\n",
    "Q7. The output of Random Forest Regressor is the predicted continuous value for each input sample.\n",
    "\n",
    "Q8. While Random Forest Regressor is primarily used for regression tasks, it can also be adapted for classification tasks by using the Random Forest Classifier variant. This variant aggregates the predictions of multiple decision trees to determine the class label of each input sample."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
